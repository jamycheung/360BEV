name_experiment: 360Mapper_mp3d
model:
    arch: 360Mapper
    backbone: segnext
    # backbone: transformer
    backbone_size: b2
    finetune: False
    n_obj_classes: 21
    ego_feature_dim: 64
    mem_feature_dim: 128
    mem_update: replace
    ego_downsample: False
    bev_h: 500
    bev_w: 500
    img_shape: [1024, 2048, 3]
    batch_size_every_processer: 1
    backbone_config:
      { 'type': 'EncoderDecoder',
        'backbone': { 'type': 'MSCAN',
                      'embed_dims': [ 64, 128, 320, 512 ],
                      'mlp_ratios': [ 8, 8, 4, 4 ],
                      'drop_rate': 0.0,
                      'drop_path_rate': 0.1,
                      'depths': [ 3, 3, 12, 3 ],
                      'norm_cfg': { 'type': 'SyncBN',
                                    'requires_grad': True },
                      'init_cfg': { 'type': 'Pretrained',
                                    'checkpoint': './checkpoints/mscan_b.pth' } },
        'decode_head': { 'type': 'LightHamHead',
                         'in_channels': [ 128, 320, 512 ],
                         'in_index': [ 1, 2, 3 ],
                         'channels': 512,
                         'ham_channels': 512,
                         'dropout_ratio': 0.1,
                         'num_classes': 21,
                         'norm_cfg': { 'type': 'GN',
                                       'num_groups': 32,
                                       'requires_grad': True },
                         'align_corners': False,
                         'loss_decode': { 'type': 'CrossEntropyLoss',
                                          'use_sigmoid': False,
                                          'loss_weight': 1.0 } },
      }

    360Attention_cfg:
      { 'type': 'BEVFormerEncoder',
        'num_layers': 2,
        'pc_range': [ -5, -5, -1, 5, 5, 1 ], # pc_range: pointcloud_range_XYZ
        'num_points_in_pillar': 1,
        'return_intermediate': False,
        'transformerlayers': { 'type': 'BEVFormerLayer',
                               'attn_cfgs': [ { 'type': 'SpatialCrossAttention', 'pc_range': [ -5, -5, -2, 5, 5, 1 ],
                                                'deformable_attention': { 'type': 'MSDeformableAttention3D', 'embed_dims': 128, 'num_heads': 4 ,'num_points': 2, 'num_levels': 1, 'sampling_offsets_th': 1}, 'embed_dims': 128 } ],
                               'feedforward_channels': 128,
                               'ffn_dropout': 0.1,
                               'operation_order': ['cross_attn', 'norm', 'ffn', 'norm'],
        }
      }

data:
    train_split: train
    val_split: val
    test_split: test

    root:   # Pls enter the address of the dataset here.

    ego_downsample: False
    feature_type: lastlayer

training:
    train_epoch: 60
    batch_size: 4
    n_workers: 8
    print_interval: 10
    optimizer:
        lr:  0.00006
        betas: [0.9, 0.999]
        weight_decay: 0.01
    scheduler:
        lr_decay_rate: 0.7
        lr_epoch_per_decay: 10

model_path:    # Your path to pre-trained model weights    # segnext b2
# model_path:  # Your path to pre-trained model weights    # segformer b2
output_dir:    ./ # /your_path_to_output/
