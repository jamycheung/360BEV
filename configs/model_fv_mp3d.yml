name_experiment: model_pano_segformer_mp3d
model:
    arch: 360Attention
    backbone: transformer    # transformer
    backbone_size: b2
    finetune: False
    n_obj_classes: 20
    ego_feature_dim: 64
    mem_feature_dim: 128
    pano_h: 512
    pano_w: 1024
    # img_shape: [ 1024, 2048, 3 ]
    360Attention_cfg:
          { 'type': 'BEVFormerEncoder_pano',
            'num_layers': 2,
            'pc_range': [ -5, -5, -1, 5, 5, 1 ], # pc_range: pointcloud_range_XYZ
            'num_points_in_pillar': 1,
            'return_intermediate': False,
            'transformerlayers': { 'type': 'BEVFormerLayer_pano',
                                   'attn_cfgs': [ { 'type': 'PanoCrossAttention', 'pc_range': [ -5, -5, -2, 5, 5, 1 ],
                                                    'deformable_attention': { 'type': 'MSDeformableAttention_pano', 'embed_dims': 128, 'num_heads': 4, 'num_points': 2, 'num_levels': 1, 'sampling_offsets_th': 1}, 'embed_dims': 128 } ],
                                   'feedforward_channels': 128,
                                   'ffn_dropout': 0.1,
                                   'operation_order': ['cross_attn', 'norm', 'ffn', 'norm'],
                                 }
          }

data:
    train_split: train
    val_split: val
    test_split: test
    root : # Pls enter the address of the dataset here.

training:
    train_epoch: 60
    batch_size: 4
    n_workers: 4
    print_interval: 10
    optimizer:
        lr:  0.00006
        betas: [0.9, 0.999]
        weight_decay: 0.001
    scheduler:
        lr_decay_rate: 0.8
        lr_epoch_per_decay: 20

model_path: # Your path to pre-trained model weights
output_dir: ./ # /your_path_to_output/
