name_experiment: model_pano_segformer_s2d3d
model:
    arch: 360Attention
    backbone: transformer
    backbone_size: b2
    finetune: False
    n_obj_classes: 13
    ego_feature_dim: 64
    # mem_feature_dim: 64
    mem_feature_dim: 128
    pano_h: 512
    pano_w: 1024
    360Attebtion_cfg:
            {'type': 'BEVFormerEncoder_pano',
            'num_layers': 2,
            'pc_range': [ -5, -5, -1, 5, 5, 1 ], # pc_range: pointcloud_range_XYZ
            'num_points_in_pillar': 1,
            'return_intermediate': False,
            'transformerlayers': { 'type': 'BEVFormerLayer_pano',
                                   'attn_cfgs': [ { 'type': 'PanoCrossAttention', 'pc_range': [ -5, -5, -2, 5, 5, 1 ],
                                                    'deformable_attention': { 'type': 'MSDeformableAttention_pano', 'embed_dims': 128, 'num_heads': 4, 'num_points': 2, 'num_levels': 1, 'sampling_offsets_th': 1}, 'embed_dims': 128 } ],
                                   'feedforward_channels': 128,
                                   'ffn_dropout': 0.1,
                                   'operation_order': ['cross_attn', 'norm', 'ffn', 'norm'],
                                 }
            }

data:
    train_split: 1_train
    val_split: 1_val
    # train_split: 2_train
    # val_split: 2_val
    # train_split: 3_train
    # val_split: 3_val

    root:  # Pls enter the address of the dataset here.

training:
    train_epoch: 100
    batch_size: 8
    n_workers: 8
    print_interval: 10
    optimizer:
        lr:  0.00006
        betas: [0.9, 0.999]
        weight_decay: 0.001
    scheduler:
        lr_decay_rate: 0.8
        lr_epoch_per_decay: 20

# model_path: # Your path to pre-trained model weights  # 3-fold
# model_path: # Your path to pre-trained model weights  # 2-fold
model_path:   # Your path to pre-trained model weights  # 1-fold
output_dir:  ./ # /your_path_to_output/
